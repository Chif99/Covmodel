{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "import numpy as np\r\n",
    "import skimage as ski\r\n",
    "from skimage import io\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpltimg\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "from PIL import Image\r\n",
    "import keras as krs\r\n",
    "import tensorflow as tf\r\n",
    "from skimage.morphology import erosion, disk\r\n",
    "from skimage.filters import threshold_triangle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "#trainin stuffs\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\r\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\r\n",
    "from keras.utils import conv_utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "dataset = []\r\n",
    "labels = []\r\n",
    "# importing the dataset first for train/test \r\n",
    "# labels are binary (1, 0)\r\n",
    "# 1 stands for infected\r\n",
    "# 0 stands for control"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# here goes the infected batch of data\r\n",
    "infected_imgs = os.listdir('E:\\DEMO\\data_set\\infected')\r\n",
    "for i, image_name in enumerate(infected_imgs):\r\n",
    "    img = cv2.imread('E:\\DEMO\\data_set\\infected\\\\' +  image_name)\r\n",
    "    img = Image.fromarray(img, mode='RGB')\r\n",
    "    img = img.resize((100, 100))\r\n",
    "    dataset.append(np.array(img))\r\n",
    "    labels.append(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "# here goes the control batch of data\r\n",
    "control_imgs = os.listdir('E:\\DEMO\\data_set\\control')\r\n",
    "for i, image_name in enumerate(control_imgs):\r\n",
    "    img = cv2.imread('E:\\DEMO\\data_set\\control\\\\' + image_name)\r\n",
    "    img = Image.fromarray(img, mode='RGB')\r\n",
    "    img = img.resize((100, 100))\r\n",
    "    dataset.append(np.array(img))\r\n",
    "    labels.append(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "# converting dataset and labels from lists to np.ndarray() for the upcoming work\r\n",
    "dataset = np.array(dataset)\r\n",
    "labels = np.array(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size = 0.20, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\r\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "#creatin za model\r\n",
    "model = Sequential()\r\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3)))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform'))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer='he_uniform'))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(64))\r\n",
    "model.add(Activation('relu'))\r\n",
    "model.add(Dropout(0.5))\r\n",
    "model.add(Dense(1))\r\n",
    "model.add(Activation('sigmoid'))\r\n",
    "#we are performing a binary classification\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\r\n",
    "print(model.summary())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 438,369\n",
      "Trainable params: 438,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 64, verbose = 1, epochs = 10, validation_data = (x_test, y_test), shuffle = False)\r\n",
    "model.save('covid_lungs_infection_model.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.7621 - accuracy: 0.3125 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.7213 - accuracy: 0.1875 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.6871 - accuracy: 0.6250 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.6864 - accuracy: 0.6875 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.7004 - accuracy: 0.3750 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6728 - accuracy: 0.5000 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.6645 - accuracy: 0.6875 - val_loss: 0.6950 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "db196df78566367d8cc66ee2d63a7f3009100341751c744c80d536d98da7595e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}